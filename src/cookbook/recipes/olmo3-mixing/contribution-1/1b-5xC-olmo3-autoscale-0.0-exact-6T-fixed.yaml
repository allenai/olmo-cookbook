name: 1b-5xC-olmo3-autoscale-0.0-exact-6T-fixed
description: 1B 5xC Olmo3-only proposed mix using Autoscale regression (rep=4 @ for 6T, drop metrics), exact (0.0) from dense fixed swarm (7c2c2dc44f0aca44)
budget: ai2/oe-base
workspace: ai2/dolma2
nodes: 4
gpus: 8
preemptible: true
max_tokens: 127939584000
sequence_length: 4096
seed: 1337
model: olmo2_1B_v2
tokenizer: dolma2
priority: high
cluster: ai2/jupiter
weka: true
rank_microbatch_size: 32768
global_batch_size: 2097152
dataset:
  sources:
  - name: arxiv
    paths:
    - s3://ai2-llm/preprocessed/proof-pile-2/v0_decontaminated/arxiv/train/allenai/dolma2-tokenizer/*.npy
    repetition_factor: 4
    target_ratio: 0.013848203670227868
  - name: dclm
    paths:
    - s3://ai2-llm/preprocessed/dclm/baseline_topic_classified_sample/*/dolma2-tokenizer/*.npy
    repetition_factor: 4
    target_ratio: 0.5919547267378987
  - name: finemath-3plus
    paths:
    - s3://ai2-llm/preprocessed/finemath/finemath-3plus/allenai/dolma2-tokenizer/*.npy
    repetition_factor: 4
    target_ratio: 0.02270517711677917
  - name: pes2o
    paths:
    - s3://ai2-llm/preprocessed/pes2o/allenai/dolma2-tokenizer/*.npy
    repetition_factor: 4
    target_ratio: 0.03903390742287415
  - name: stack-edu
    paths:
    - s3://ai2-llm/preprocessed/stack-edu/allenai/dolma2-tokenizer/**/*.npy
    repetition_factor: 4
    target_ratio: 0.09123311966043676
  - name: wikipedia
    paths:
    - s3://ai2-llm/preprocessed/structured-wikipedia/concat_with_links/allenai/dolma2-tokenizer/*.npy
    repetition_factor: 4
    target_ratio: 0.006712034285476129
  - name: s2pdfv1
    paths:
    - s3://ai2-llm/preprocessed/s2pdf_dedupe_minhash_v1_with_no_pii_basic_quality_datadelve/**/*.npy
    repetition_factor: 4
    target_ratio: 0.23451280689055237
