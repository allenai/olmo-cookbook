# Sampled 35 files with 131,615,119,476 tokens (pool target: 1,000,000,000,000, scaled target: 127,939,584,000, total size: 1,957,441,643,823)
budget: ai2/oe-base
cluster: ai2/augusta-google-1
dataset:
  sources:
  - name: medium
    paths:
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-094-00003.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-109-00002.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-024-00002.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-053-00000.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-105-00003.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-044-00003.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-078-00000.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-052-00003.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-056-00000.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-018-00003.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-028-00003.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-080-00003.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-045-00003.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-030-00003.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-092-00001.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-067-00000.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-021-00000.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-010-00000.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-043-00003.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-115-00002.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-027-00001.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-081-00002.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-087-00003.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-005-00000.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-058-00000.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-037-00000.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-117-00000.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-080-00000.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-006-00002.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-088-00003.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-075-00002.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-081-00000.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-040-00000.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-033-00000.npy
    - s3://ai2-llm/preprocessed/Nemotron-CC/v0/quality=medium/kind=actual/kind2=actual/allenai/dolma2-tokenizer/part-113-00002.npy
    target_ratio: 1
description: Baseline Nemotron CC, Medium subset. https://arxiv.org/abs/2412.02595,
  for 1B-5xC with 1000B target pool
downstream_evaluators:
- olmo2_dev_1b
global_batch_size: 2097152
gpus: 8
lm_evaluator: true
max_tokens: 127939584000
model: olmo2_1B_v2
name: nemotron-cc-medium-1B-5xC-1000B
nodes: 2
preemptible: true
priority: high
rank_microbatch_size: 32768
seed: 1337
sequence_length: 4096
tokenizer: dolma2
weka: false
workspace: ai2/dolma2
