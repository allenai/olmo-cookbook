# Sampled 35 files with 130,681,563,869 tokens (pool target: 2,000,000,000,000, scaled target: 127,939,584,000, total size: 11,567,932,920,105)
budget: ai2/oe-base
cluster: ai2/augusta-google-1
dataset:
  sources:
  - name: fineweb
    paths:
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2021-49/part-14-00001.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2021-39/part-05-00001.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2017-22/part-09-00000.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2022-40/part-05-00002.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2023-50/part-06-00003.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2021-17/part-02-00000.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2016-18/part-04-00000.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2015-40/part-13-00001.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2020-24/part-00-00000.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2022-40/part-01-00002.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2015-27/part-11-00000.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2021-25/part-02-00000.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2017-22/part-00-00001.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2017-30/part-05-00001.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2016-50/part-15-00000.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2013-20/part-13-00000.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2015-11/part-13-00000.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2015-18/part-03-00001.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2020-10/part-06-00001.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2017-43/part-08-00002.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2017-04/part-12-00002.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2017-13/part-04-00002.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2023-40/part-01-00000.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2016-30/part-03-00001.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2017-26/part-04-00000.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2017-13/part-11-00000.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2015-11/part-07-00001.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2021-17/part-06-00001.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2021-43/part-01-00001.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2017-39/part-12-00001.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2014-52/part-04-00000.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2014-49/part-11-00001.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2020-10/part-05-00001.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2020-24/part-13-00001.npy
    - s3://ai2-llm/preprocessed/fineweb/raw/allenai/dolma2-tokenizer/CC-MAIN-2021-17/part-10-00000.npy
    target_ratio: 1
description: FineWeb. https://arxiv.org/abs/2406.17557
downstream_evaluators:
- olmo2_dev_1b
global_batch_size: 2097152
gpus: 8
lm_evaluator: true
max_tokens: 127939584000
model: olmo2_1B_v2
name: fineweb
nodes: 2
preemptible: true
priority: high
rank_microbatch_size: 32768
seed: 1337
sequence_length: 4096
tokenizer: dolma2
weka: false
workspace: ai2/dolma2
