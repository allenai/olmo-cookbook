{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "914d180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/Users/ianm/projects/olmo-cookbook/baseline_sampler_data.json','r') as fin:\n",
    "    data = json.load(fin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57b1e841",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_to_remove = [key for key in data.keys() if key.startswith(\"mt_mbpp\") and key not in (\"mt_mbpp\", \"mt_mbpp:bpb\")]\n",
    "for key in keys_to_remove:\n",
    "    del data[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2aa51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/ianm/projects/olmo-cookbook/baseline_sampler_data.json','w') as fout:\n",
    "    json.dump(data, fout, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "277713fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mt_mbpp\n",
      "mt_mbpp:bpb\n",
      "codex_humaneval:3shot:bpb::none\n",
      "lab_bench_dbqa\n",
      "lab_bench_dbqa:bpb\n",
      "lab_bench_protocolqa\n",
      "lab_bench_protocolqa:bpb\n",
      "lambada\n",
      "lambada:bpb\n",
      "mbpp:3shot:bpb::none\n",
      "minerva_math_algebra::olmes\n",
      "minerva_math_algebra:bpb::olmes\n",
      "minerva_math_counting_and_probability::olmes\n",
      "minerva_math_counting_and_probability:bpb::olmes\n",
      "minerva_math_geometry::olmes\n",
      "minerva_math_geometry:bpb::olmes\n",
      "minerva_math_intermediate_algebra::olmes\n",
      "minerva_math_intermediate_algebra:bpb::olmes\n",
      "minerva_math_number_theory::olmes\n",
      "minerva_math_number_theory:bpb::olmes\n",
      "minerva_math_prealgebra::olmes\n",
      "minerva_math_prealgebra:bpb::olmes\n",
      "minerva_math_precalculus::olmes\n",
      "minerva_math_precalculus:bpb::olmes\n",
      "arc_challenge:rc::olmes:full\n",
      "arc_challenge:bpb::olmes:full\n",
      "arc_easy:rc::olmes:full\n",
      "arc_easy:bpb::olmes:full\n",
      "basic_skills_arithmetic:rc::olmes\n",
      "basic_skills_arithmetic:bpb::olmes\n",
      "basic_skills_coding:rc::olmes\n",
      "basic_skills_coding:bpb::olmes\n",
      "basic_skills_common_knowledge:rc::olmes\n",
      "basic_skills_common_knowledge:bpb::olmes\n",
      "basic_skills_logical_reasoning:rc::olmes\n",
      "basic_skills_logical_reasoning:bpb::olmes\n",
      "basic_skills_string_operations:rc::olmes\n",
      "basic_skills_string_operations:bpb::olmes\n",
      "basic_skills_pattern:rc::olmes\n",
      "basic_skills_pattern:bpb::olmes\n",
      "coqa:rc::gen2mc\n",
      "coqa:bpb::gen2mc\n",
      "csqa:rc::olmes:full\n",
      "csqa:bpb::olmes:full\n",
      "drop:rc::gen2mc\n",
      "drop:bpb::gen2mc\n",
      "hellaswag:rc::olmes:full\n",
      "hellaswag:bpb::olmes:full\n",
      "jeopardy:rc::gen2mc\n",
      "jeopardy:bpb::gen2mc\n",
      "medmcqa:rc::none\n",
      "medmcqa:bpb::none\n",
      "medqa_en:rc::none\n",
      "medqa_en:bpb::none\n",
      "mmlu_abstract_algebra:rc::olmes\n",
      "mmlu_abstract_algebra:bpb::olmes\n",
      "mmlu_anatomy:rc::olmes\n",
      "mmlu_anatomy:bpb::olmes\n",
      "mmlu_astronomy:rc::olmes\n",
      "mmlu_astronomy:bpb::olmes\n",
      "mmlu_business_ethics:rc::olmes\n",
      "mmlu_business_ethics:bpb::olmes\n",
      "mmlu_clinical_knowledge:rc::olmes\n",
      "mmlu_clinical_knowledge:bpb::olmes\n",
      "mmlu_college_biology:rc::olmes\n",
      "mmlu_college_biology:bpb::olmes\n",
      "mmlu_college_chemistry:rc::olmes\n",
      "mmlu_college_chemistry:bpb::olmes\n",
      "mmlu_college_computer_science:rc::olmes\n",
      "mmlu_college_computer_science:bpb::olmes\n",
      "mmlu_college_mathematics:rc::olmes\n",
      "mmlu_college_mathematics:bpb::olmes\n",
      "mmlu_college_medicine:rc::olmes\n",
      "mmlu_college_medicine:bpb::olmes\n",
      "mmlu_college_physics:rc::olmes\n",
      "mmlu_college_physics:bpb::olmes\n",
      "mmlu_computer_security:rc::olmes\n",
      "mmlu_computer_security:bpb::olmes\n",
      "mmlu_conceptual_physics:rc::olmes\n",
      "mmlu_conceptual_physics:bpb::olmes\n",
      "mmlu_econometrics:rc::olmes\n",
      "mmlu_econometrics:bpb::olmes\n",
      "mmlu_electrical_engineering:rc::olmes\n",
      "mmlu_electrical_engineering:bpb::olmes\n",
      "mmlu_elementary_mathematics:rc::olmes\n",
      "mmlu_elementary_mathematics:bpb::olmes\n",
      "mmlu_formal_logic:rc::olmes\n",
      "mmlu_formal_logic:bpb::olmes\n",
      "mmlu_global_facts:rc::olmes\n",
      "mmlu_global_facts:bpb::olmes\n",
      "mmlu_high_school_biology:rc::olmes\n",
      "mmlu_high_school_biology:bpb::olmes\n",
      "mmlu_high_school_chemistry:rc::olmes\n",
      "mmlu_high_school_chemistry:bpb::olmes\n",
      "mmlu_high_school_computer_science:rc::olmes\n",
      "mmlu_high_school_computer_science:bpb::olmes\n",
      "mmlu_high_school_european_history:rc::olmes\n",
      "mmlu_high_school_european_history:bpb::olmes\n",
      "mmlu_high_school_geography:rc::olmes\n",
      "mmlu_high_school_geography:bpb::olmes\n",
      "mmlu_high_school_government_and_politics:rc::olmes\n",
      "mmlu_high_school_government_and_politics:bpb::olmes\n",
      "mmlu_high_school_macroeconomics:rc::olmes\n",
      "mmlu_high_school_macroeconomics:bpb::olmes\n",
      "mmlu_high_school_mathematics:rc::olmes\n",
      "mmlu_high_school_mathematics:bpb::olmes\n",
      "mmlu_high_school_microeconomics:rc::olmes\n",
      "mmlu_high_school_microeconomics:bpb::olmes\n",
      "mmlu_high_school_physics:rc::olmes\n",
      "mmlu_high_school_physics:bpb::olmes\n",
      "mmlu_high_school_psychology:rc::olmes\n",
      "mmlu_high_school_psychology:bpb::olmes\n",
      "mmlu_high_school_statistics:rc::olmes\n",
      "mmlu_high_school_statistics:bpb::olmes\n",
      "mmlu_high_school_us_history:rc::olmes\n",
      "mmlu_high_school_us_history:bpb::olmes\n",
      "mmlu_high_school_world_history:rc::olmes\n",
      "mmlu_high_school_world_history:bpb::olmes\n",
      "mmlu_human_aging:rc::olmes\n",
      "mmlu_human_aging:bpb::olmes\n",
      "mmlu_human_sexuality:rc::olmes\n",
      "mmlu_human_sexuality:bpb::olmes\n",
      "mmlu_international_law:rc::olmes\n",
      "mmlu_international_law:bpb::olmes\n",
      "mmlu_jurisprudence:rc::olmes\n",
      "mmlu_jurisprudence:bpb::olmes\n",
      "mmlu_logical_fallacies:rc::olmes\n",
      "mmlu_logical_fallacies:bpb::olmes\n",
      "mmlu_machine_learning:rc::olmes\n",
      "mmlu_machine_learning:bpb::olmes\n",
      "mmlu_management:rc::olmes\n",
      "mmlu_management:bpb::olmes\n",
      "mmlu_marketing:rc::olmes\n",
      "mmlu_marketing:bpb::olmes\n",
      "mmlu_medical_genetics:rc::olmes\n",
      "mmlu_medical_genetics:bpb::olmes\n",
      "mmlu_miscellaneous:rc::olmes\n",
      "mmlu_miscellaneous:bpb::olmes\n",
      "mmlu_moral_disputes:rc::olmes\n",
      "mmlu_moral_disputes:bpb::olmes\n",
      "mmlu_moral_scenarios:rc::olmes\n",
      "mmlu_moral_scenarios:bpb::olmes\n",
      "mmlu_nutrition:rc::olmes\n",
      "mmlu_nutrition:bpb::olmes\n",
      "mmlu_philosophy:rc::olmes\n",
      "mmlu_philosophy:bpb::olmes\n",
      "mmlu_prehistory:rc::olmes\n",
      "mmlu_prehistory:bpb::olmes\n",
      "mmlu_professional_accounting:rc::olmes\n",
      "mmlu_professional_accounting:bpb::olmes\n",
      "mmlu_professional_law:rc::olmes\n",
      "mmlu_professional_law:bpb::olmes\n",
      "mmlu_professional_medicine:rc::olmes\n",
      "mmlu_professional_medicine:bpb::olmes\n",
      "mmlu_professional_psychology:rc::olmes\n",
      "mmlu_professional_psychology:bpb::olmes\n",
      "mmlu_public_relations:rc::olmes\n",
      "mmlu_public_relations:bpb::olmes\n",
      "mmlu_security_studies:rc::olmes\n",
      "mmlu_security_studies:bpb::olmes\n",
      "mmlu_sociology:rc::olmes\n",
      "mmlu_sociology:bpb::olmes\n",
      "mmlu_us_foreign_policy:rc::olmes\n",
      "mmlu_us_foreign_policy:bpb::olmes\n",
      "mmlu_virology:rc::olmes\n",
      "mmlu_virology:bpb::olmes\n",
      "mmlu_world_religions:rc::olmes\n",
      "mmlu_world_religions:bpb::olmes\n",
      "naturalqs:rc::gen2mc\n",
      "naturalqs:bpb::gen2mc\n",
      "piqa:rc::olmes:full\n",
      "piqa:bpb::olmes:full\n",
      "qasper_yesno:rc::olmes\n",
      "qasper_yesno:bpb::olmes\n",
      "sciq:rc::olmo3\n",
      "sciq:bpb::olmo3\n",
      "sciriff_yesno:rc::olmes\n",
      "sciriff_yesno:bpb::olmes\n",
      "socialiqa:rc::olmes:full\n",
      "socialiqa:bpb::olmes:full\n",
      "squad:rc::gen2mc\n",
      "squad:bpb::gen2mc\n",
      "winogrande:rc::olmes:full\n",
      "winogrande:bpb::olmes:full\n"
     ]
    }
   ],
   "source": [
    "for k in data.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068ca7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# Construct data set fresh\n",
    "models_data = [\n",
    "    {\"model\": \"olmo2-1b\", \"accuracy\": 0.584, \"params\": 1e9, \"tokens\": 4e12},\n",
    "    {\"model\": \"olmo2-7b\", \"accuracy\": 0.687, \"params\": 7e9, \"tokens\": 4e12},\n",
    "    {\"model\": \"olmo2-13b\", \"accuracy\": 0.73,  \"params\": 13e9, \"tokens\": 5e12},\n",
    "    {\"model\": \"meta-llama/Llama-2-13b-hf\", \"accuracy\": 0.749, \"params\": 13e9, \"tokens\": 2e12},\n",
    "    {\"model\": \"deepseek-ai/deepseek-llm-7b-base\", \"accuracy\": 0.723, \"params\": 7e9, \"tokens\": 2e12},\n",
    "    {\"model\": \"Qwen/Qwen2.5-7B\", \"accuracy\": 0.679, \"params\": 7e9, \"tokens\": 18e12},\n",
    "    {\"model\": \"allenai/DataDecide-dclm-baseline-1B\", \"accuracy\": 0.614, \"params\": 1e9, \"tokens\": 1e11},\n",
    "    {\"model\": \"allenai/DataDecide-dclm-baseline-50p-dolma1.7-50p-1B\", \"accuracy\": 0.604, \"params\": 1e9, \"tokens\": 1e11},\n",
    "    {\"model\": \"allenai/DataDecide-dolma1_7-1B\", \"accuracy\": 0.561, \"params\": 1e9, \"tokens\": 1e11},\n",
    "    {\"model\": \"olmo2-1b-step20000\", \"accuracy\": 0.58,  \"params\": 1e9, \"tokens\": 42e9},\n",
    "    {\"model\": \"olmo2-1b-step21000\", \"accuracy\": 0.596, \"params\": 1e9, \"tokens\": 45e9},\n",
    "    {\"model\": \"olmo2-1b-step22000\", \"accuracy\": 0.599, \"params\": 1e9, \"tokens\": 47e9},\n",
    "    {\"model\": \"olmo2-1b-step23000\", \"accuracy\": 0.598, \"params\": 1e9, \"tokens\": 49e9},\n",
    "    {\"model\": \"meta-llama/Meta-Llama-3-8B\", \"accuracy\": 0.751, \"params\": 8e9, \"tokens\": 15e12},\n",
    "    {\"model\": \"meta-llama/Meta-Llama-3.1-8B\", \"accuracy\": 0.749, \"params\": 8e9, \"tokens\": 15e12},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(models_data)\n",
    "\n",
    "# Metrics\n",
    "df[\"compute\"] = 6 * df[\"params\"] * df[\"tokens\"]\n",
    "df[\"t2p_ratio\"] = df[\"tokens\"] / df[\"params\"]\n",
    "\n",
    "# Label renaming\n",
    "def rename(model):\n",
    "    mapping = {\n",
    "        \"allenai/DataDecide-dclm-baseline-1B\": \"DataDecide-DCLM\",\n",
    "        \"allenai/DataDecide-dclm-baseline-50p-dolma1.7-50p-1B\": \"DataDecide-DCLM-Dolma-even-mix\",\n",
    "        \"allenai/DataDecide-dolma1_7-1B\": \"DataDecide-Dolma\",\n",
    "        \"meta-llama/Meta-Llama-3-8B\": \"Llama-3-8B\",\n",
    "        \"meta-llama/Meta-Llama-3.1-8B\": \"Llama-3.1-8B\",\n",
    "    }\n",
    "    if model in mapping:\n",
    "        return mapping[model]\n",
    "    return model.split(\"/\")[-1]\n",
    "\n",
    "df[\"label\"] = df[\"model\"].apply(rename)\n",
    "\n",
    "# Marker mapping\n",
    "marker_map = {\n",
    "    \"DataDecide-DCLM\": '^',\n",
    "    \"DataDecide-DCLM-Dolma-even-mix\": '^',\n",
    "    \"DataDecide-Dolma\": '^',\n",
    "    \"olmo2-1b\": 's',\n",
    "    \"olmo2-7b\": 's',\n",
    "    \"olmo2-13b\": 's',\n",
    "    \"Llama-2-13b-hf\": 'o',\n",
    "    \"deepseek-llm-7b-base\": 'X',\n",
    "    \"Qwen2.5-7B\": 'D',\n",
    "    \"Llama-3-8B\": 'v',\n",
    "    \"Llama-3.1-8B\": 'P'\n",
    "}\n",
    "\n",
    "# Filter checkpoints\n",
    "ckpt_mask = df[\"model\"].str.contains(\"olmo2-1b-step\")\n",
    "plot_df = df[~ckpt_mask].copy()\n",
    "\n",
    "# Compute accuracy std for olmo2-1b\n",
    "acc_std = df.loc[ckpt_mask, \"accuracy\"].append(pd.Series([plot_df.loc[plot_df[\"model\"] == \"olmo2-1b\", \"accuracy\"].iloc[0]])).std(ddof=0)\n",
    "\n",
    "# Color normalization\n",
    "norm = Normalize(vmin=plot_df[\"t2p_ratio\"].min(), vmax=plot_df[\"t2p_ratio\"].max())\n",
    "cmap = cm.get_cmap(\"viridis\")\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "# Scatter each point\n",
    "for _, row in plot_df.iterrows():\n",
    "    label = row[\"label\"]\n",
    "    marker = marker_map.get(label, '*')\n",
    "    color = cmap(norm(row[\"t2p_ratio\"]))\n",
    "    plt.scatter(row[\"compute\"], row[\"accuracy\"], marker=marker, color=color, s=70, edgecolor='k')\n",
    "    plt.annotate(label, (row[\"compute\"], row[\"accuracy\"]), fontsize=8, xytext=(4,2), textcoords='offset points')\n",
    "\n",
    "# Error bar\n",
    "olmo1b = plot_df[plot_df[\"model\"] == \"olmo2-1b\"].iloc[0]\n",
    "plt.errorbar(olmo1b[\"compute\"], olmo1b[\"accuracy\"], yerr=acc_std, fmt=marker_map[\"olmo2-1b\"],\n",
    "             color=cmap(norm(olmo1b[\"t2p_ratio\"])), markersize=7, capsize=5, markeredgecolor='k')\n",
    "\n",
    "# Connect olmo2 line\n",
    "olmo_series = plot_df[plot_df[\"model\"].isin([\"olmo2-1b\",\"olmo2-7b\",\"olmo2-13b\"])].sort_values(\"compute\")\n",
    "plt.plot(olmo_series[\"compute\"], olmo_series[\"accuracy\"], linestyle='--', color='black', alpha=0.6)\n",
    "\n",
    "# Colorbar\n",
    "cbar = plt.colorbar(cm.ScalarMappable(norm=norm, cmap=cmap))\n",
    "cbar.set_label(\"Token / Parameter Ratio\")\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Compute (6ND, FLOPs, log scale)\")\n",
    "plt.ylabel(\"LAMBADA Accuracy\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plot_path = Path(\"/mnt/data/compute_vs_lambada_final.png\")\n",
    "plt.savefig(plot_path, dpi=300)\n",
    "plt.close()\n",
    "\n",
    "display_dataframe_to_user(\"Final plot data\", plot_df[[\"label\",\"accuracy\",\"compute\",\"t2p_ratio\"]])\n",
    "\n",
    "plot_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88baef94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize\n",
    "from pathlib import Path\n",
    "from ace_tools import display_dataframe_to_user\n",
    "\n",
    "# Try to import adjustText for label adjustment\n",
    "try:\n",
    "    from adjustText import adjust_text\n",
    "    ADJUST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    ADJUST_AVAILABLE = False\n",
    "\n",
    "# Full JSON data from user (pasted entirely)\n",
    "json_str = \"\"\"\n",
    "{\"lambada\": {\"Meta-Llama-3-8B\": 0.7634387735299826, \"Meta-Llama-3.1-8B\": 0.7545119347952649, \"allenai--OLMo-2-1124-13B--stage2-ingredient4-step35773-tokens300B\": 0.727149233456239, \"allenai--OLMo-2-1124-13B--stage2-ingredient4-step34000-tokens286B\": 0.725790801474869, \"deepseek-llm-7b-base\": 0.725790801474869, \"allenai--OLMo-2-1124-13B--stage2-ingredient4-step33000-tokens277B\": 0.7254026780516204, \"allenai--OLMo-2-1124-13B--stage2-ingredient4-step35000-tokens294B\": 0.7248204929167475, \"allenai--OLMo-2-1124-13B--stage2-ingredient4-step32000-tokens269B\": 0.724432369493499, \"Qwen2.5-7B\": 0.7026974577915778, \"allenai--OLMo-2-1124-7B--stage2-ingredient3-step9000-tokens38B\": 0.7021152726567048, \"allenai--OLMo-2-1124-7B--stage2-ingredient3-step11931-tokens50B\": 0.701533087521832, \"allenai--OLMo-2-1124-7B--stage2-ingredient3-step10000-tokens42B\": 0.6988162235590918, \"allenai--OLMo-2-1124-7B--stage2-ingredient3-step11000-tokens47B\": 0.6964874830196003, \"allenai--OLMo-2-1124-7B--stage2-ingredient3-step8000-tokens34B\": 0.6951290510382302, \"DataDecide-dclm-baseline-1B\": 0.6155637492722685, \"DataDecide-dclm-baseline-50p-dolma1.7-50p-1B\": 0.6134290704444013, \"allenai--OLMo-2-0425-1B--stage2-ingredient3-step21000-tokens45B\": 0.6015913060353192, \"allenai--OLMo-2-0425-1B--stage2-ingredient3-step22000-tokens47B\": 0.5973219483795847, \"allenai--OLMo-2-0425-1B--stage2-ingredient3-step23000-tokens49B\": 0.5971278866679605, \"allenai--OLMo-2-0425-1B--stage2-ingredient3-step23852-tokens51B\": 0.5969338249563361, \"allenai--OLMo-2-0425-1B--stage2-ingredient3-step20000-tokens42B\": 0.5835435668542597, \"DataDecide-dolma1_7-1B\": 0.562196778575587}}\n",
    "\"\"\"\n",
    "data = json.loads(json_str)\n",
    "acc_dict = data[\"lambada\"]\n",
    "\n",
    "# Separate OLMo checkpoint groups\n",
    "olmo_ckpts = {\n",
    "    \"olmo2-1b\": [],\n",
    "    \"olmo2-7b\": [],\n",
    "    \"olmo2-13b\": []\n",
    "}\n",
    "other = {}\n",
    "\n",
    "for name, acc in acc_dict.items():\n",
    "    if name.startswith(\"allenai--OLMo-2-0425-1B\"):\n",
    "        olmo_ckpts[\"olmo2-1b\"].append(acc)\n",
    "    elif name.startswith(\"allenai--OLMo-2-1124-7B\"):\n",
    "        olmo_ckpts[\"olmo2-7b\"].append(acc)\n",
    "    elif name.startswith(\"allenai--OLMo-2-1124-13B\"):\n",
    "        olmo_ckpts[\"olmo2-13b\"].append(acc)\n",
    "    else:\n",
    "        other[name] = acc\n",
    "\n",
    "# Base parameter/token values (original, fixed)\n",
    "base_info = {\n",
    "    \"olmo2-1b\": (1e9, 4e12),\n",
    "    \"olmo2-7b\": (7e9, 4e12),\n",
    "    \"olmo2-13b\": (13e9, 5e12),\n",
    "    \"Meta-Llama-3-8B\": (8e9, 15e12),\n",
    "    \"Meta-Llama-3.1-8B\": (8e9, 15e12),\n",
    "    \"deepseek-llm-7b-base\": (7e9, 2e12),\n",
    "    \"Qwen2.5-7B\": (7e9, 18e12),\n",
    "    \"DataDecide-dclm-baseline-1B\": (1e9, 1e11),\n",
    "    \"DataDecide-dclm-baseline-50p-dolma1.7-50p-1B\": (1e9, 1e11),\n",
    "    \"DataDecide-dolma1_7-1B\": (1e9, 1e11),\n",
    "    \"Llama-2-13b-hf\": (13e9, 2e12, 0.749)\n",
    "}\n",
    "\n",
    "# Build dataframe\n",
    "records = []\n",
    "for size, accs in olmo_ckpts.items():\n",
    "    if accs:\n",
    "        params, tokens = base_info[size]\n",
    "        records.append({\n",
    "            \"label\": size,\n",
    "            \"accuracy\": np.mean(accs),\n",
    "            \"std\": np.std(accs, ddof=0),\n",
    "            \"params\": params,\n",
    "            \"tokens\": tokens\n",
    "        })\n",
    "\n",
    "label_map = {\n",
    "    \"Meta-Llama-3-8B\": \"Llama-3-8B\",\n",
    "    \"Meta-Llama-3.1-8B\": \"Llama-3.1-8B\",\n",
    "    \"deepseek-llm-7b-base\": \"deepseek-llm-7b-base\",\n",
    "    \"Qwen2.5-7B\": \"Qwen2.5-7B\",\n",
    "    \"DataDecide-dclm-baseline-1B\": \"DataDecide-DCLM\",\n",
    "    \"DataDecide-dclm-baseline-50p-dolma1.7-50p-1B\": \"DataDecide-DCLM-Dolma-even-mix\",\n",
    "    \"DataDecide-dolma1_7-1B\": \"DataDecide-Dolma\"\n",
    "}\n",
    "for model, acc in other.items():\n",
    "    params, tokens = base_info[model][:2]\n",
    "    records.append({\n",
    "        \"label\": label_map.get(model, model.split(\"/\")[-1]),\n",
    "        \"accuracy\": acc,\n",
    "        \"std\": 0.0,\n",
    "        \"params\": params,\n",
    "        \"tokens\": tokens\n",
    "    })\n",
    "records.append({\n",
    "    \"label\": \"Llama-2-13b-hf\",\n",
    "    \"accuracy\": base_info[\"Llama-2-13b-hf\"][2],\n",
    "    \"std\": 0.0,\n",
    "    \"params\": base_info[\"Llama-2-13b-hf\"][0],\n",
    "    \"tokens\": base_info[\"Llama-2-13b-hf\"][1]\n",
    "})\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "df[\"compute\"] = 6 * df[\"params\"] * df[\"tokens\"]\n",
    "df[\"t2p_ratio\"] = df[\"tokens\"] / df[\"params\"]\n",
    "\n",
    "# Marker mapping\n",
    "marker_map = {\n",
    "    \"olmo2-1b\": 's',\n",
    "    \"olmo2-7b\": 's',\n",
    "    \"olmo2-13b\": 's',\n",
    "    \"DataDecide-DCLM\": '^',\n",
    "    \"DataDecide-DCLM-Dolma-even-mix\": '^',\n",
    "    \"DataDecide-Dolma\": '^',\n",
    "    \"Llama-2-13b-hf\": 'o',\n",
    "    \"deepseek-llm-7b-base\": 'X',\n",
    "    \"Qwen2.5-7B\": 'D',\n",
    "    \"Llama-3-8B\": 'v',\n",
    "    \"Llama-3.1-8B\": 'P'\n",
    "}\n",
    "\n",
    "# Plot\n",
    "norm = Normalize(vmin=df[\"t2p_ratio\"].min(), vmax=df[\"t2p_ratio\"].max())\n",
    "cmap = cm.get_cmap(\"viridis\")\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "texts = []\n",
    "points = []\n",
    "\n",
    "# Separate olmo df\n",
    "olmo_df = df[df[\"label\"].isin([\"olmo2-1b\",\"olmo2-7b\",\"olmo2-13b\"])].sort_values(\"compute\")\n",
    "x_olmo = olmo_df[\"compute\"].values\n",
    "y_olmo = olmo_df[\"accuracy\"].values\n",
    "y_std = olmo_df[\"std\"].values\n",
    "\n",
    "# Plot OLMo shaded band\n",
    "plt.fill_between(x_olmo, y_olmo - y_std, y_olmo + y_std, color='gray', alpha=0.25)\n",
    "plt.plot(x_olmo, y_olmo, linestyle='--', color='black', alpha=0.8)\n",
    "\n",
    "# Scatter all points\n",
    "for _, row in df.iterrows():\n",
    "    color = cmap(norm(row[\"t2p_ratio\"]))\n",
    "    marker = marker_map.get(row[\"label\"], '*')\n",
    "    sct = plt.scatter(row[\"compute\"], row[\"accuracy\"], marker=marker, color=color, s=70, edgecolor='k')\n",
    "    points.append(sct)\n",
    "    txt = plt.text(row[\"compute\"], row[\"accuracy\"], row[\"label\"], fontsize=8)\n",
    "    texts.append(txt)\n",
    "\n",
    "# Adjust labels if adjustText available\n",
    "if ADJUST_AVAILABLE:\n",
    "    adjust_text(texts, x=df[\"compute\"].values, y=df[\"accuracy\"].values,\n",
    "                arrowprops=dict(arrowstyle=\"-\", color='gray', lw=0.5))\n",
    "else:\n",
    "    # fallback: offset text slightly and draw simple line\n",
    "    for txt in texts:\n",
    "        x, y = txt.get_position()\n",
    "        txt.set_position((x*1.05, y*1.02))\n",
    "        plt.annotate(\"\", xy=(x, y), xytext=(x*1.05, y*1.02),\n",
    "                     arrowprops=dict(arrowstyle=\"-\", color='gray', lw=0.5))\n",
    "\n",
    "# Colorbar\n",
    "cbar = plt.colorbar(cm.ScalarMappable(norm=norm, cmap=cmap))\n",
    "cbar.set_label(\"Token / Parameter Ratio\")\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Compute (6ND, FLOPs, log scale)\")\n",
    "plt.ylabel(\"LAMBADA Accuracy\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plot_path = Path(\"/mnt/data/compute_vs_lambada_leaderlines.png\")\n",
    "plt.savefig(plot_path, dpi=300)\n",
    "plt.close()\n",
    "\n",
    "display_dataframe_to_user(\"Dataset for leader line plot\", df[[\"label\",\"accuracy\",\"std\",\"compute\"]])\n",
    "\n",
    "plot_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "olmo-cookbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
